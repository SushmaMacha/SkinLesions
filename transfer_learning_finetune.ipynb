{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "transfer_learning_finetune.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SushmaMacha/SkinLesions/blob/master/transfer_learning_finetune.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "-jQgMc6K2Clx",
        "colab_type": "code",
        "outputId": "cbd17b58-252e-4ec9-dbaa-69ed13387009",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "!ln -s gdrive/'My Drive'/SJSU/'machine learning'/'CMPE257 Fall2018 Team Project'/Code/data data\n",
        "!ln -s gdrive/'My Drive'/SJSU/'machine learning'/'CMPE257 Fall2018 Team Project'/Code code"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "xbfBeEbT2Yaz",
        "colab_type": "code",
        "outputId": "f5a814b6-9a9a-4a11-95d3-65d473ed1ad0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2167
        }
      },
      "cell_type": "code",
      "source": [
        "from keras import applications\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras import optimizers, Model\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dropout, Flatten, Dense, Input\n",
        "from keras import backend as K\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "\n",
        "# path to the model weights files.\n",
        "#weights_path = '../keras/examples/vgg16_weights.h5'\n",
        "top_model_weights_path = 'data/bottleneck_fc_model.h5'\n",
        "# dimensions of our images.\n",
        "img_width, img_height = 150, 150\n",
        "\n",
        "train_data_dir = 'data/train'\n",
        "validation_data_dir = 'data/val'\n",
        "nb_train_samples = 2*800\n",
        "nb_validation_samples = 2*192\n",
        "epochs = 50\n",
        "batch_size = 16\n",
        "\n",
        "# build the VGG16 network\n",
        "if K.image_data_format() == 'channels_first':\n",
        "    input_shape = (3, img_width, img_height)\n",
        "else:\n",
        "    input_shape = (img_width, img_height, 3)\n",
        "vgg = applications.VGG16(weights='imagenet', include_top=False, input_shape=input_shape)\n",
        "weights = vgg.get_weights()\n",
        "config = vgg.get_config()\n",
        "model = Sequential.from_config(config)\n",
        "model.set_weights(weights)\n",
        "\n",
        "model.add(Flatten(input_shape=model.output_shape[1:]))\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "# build a classifier model to put on top of the convolutional model\n",
        "#top_model = Sequential()\n",
        "#top_model.add(Flatten(input_shape=model.output_shape[1:]))\n",
        "#top_model.add(Dense(256, activation='relu'))\n",
        "#top_model.add(Dropout(0.5))\n",
        "#top_model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# note that it is necessary to start with a fully-trained\n",
        "# classifier, including the top classifier,\n",
        "# in order to successfully do fine-tuning\n",
        "model.load_weights(top_model_weights_path, by_name=True)\n",
        "\n",
        "\n",
        "# add the model on top of the convolutional base\n",
        "#model.add(top_model)\n",
        "#model = Model(inputs=model.inputs, outputs= model1.outputs)\n",
        "\n",
        "\n",
        "# set the first 25 layers (up to the last conv block)\n",
        "# to non-trainable (weights will not be updated)\n",
        "for layer in model.layers[:14]:\n",
        "    layer.trainable = False\n",
        "\n",
        "model.summary()\n",
        "\n",
        "\n",
        "# compile the model with a SGD/momentum optimizer\n",
        "# and a very slow learning rate.\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=optimizers.SGD(lr=1e-4, momentum=0.9),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# prepare data augmentation configuration\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1. / 255,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True)\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_data_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary')\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "    validation_data_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary')\n",
        "\n",
        "# fine-tune the model\n",
        "\n",
        "checkpoint = ModelCheckpoint('data/fine_tune_aug.h5', monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
        "early = EarlyStopping(monitor='val_acc', min_delta=0, patience=10, verbose=1, mode='auto')\n",
        "\n",
        "model.fit_generator(\n",
        "    train_generator,\n",
        "    steps_per_epoch = nb_train_samples // batch_size,\n",
        "    epochs=epochs,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=nb_validation_samples,\n",
        "    callbacks = [checkpoint, early]\n",
        ")\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "block1_conv1 (Conv2D)        (None, 150, 150, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 150, 150, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 75, 75, 64)        0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 75, 75, 128)       73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 75, 75, 128)       147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 37, 37, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 37, 37, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 37, 37, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 37, 37, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 18, 18, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 18, 18, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 9, 9, 512)         0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 4, 4, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 8192)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 256)               2097408   \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 257       \n",
            "=================================================================\n",
            "Total params: 16,812,353\n",
            "Trainable params: 9,177,089\n",
            "Non-trainable params: 7,635,264\n",
            "_________________________________________________________________\n",
            "Found 1600 images belonging to 2 classes.\n",
            "Found 384 images belonging to 2 classes.\n",
            "Epoch 1/50\n",
            "100/100 [==============================] - 1789s 18s/step - loss: 0.3164 - acc: 0.8669 - val_loss: 0.3769 - val_acc: 0.8724\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.87240, saving model to data/fine_tune_aug.h5\n",
            "Epoch 2/50\n",
            "100/100 [==============================] - 1508s 15s/step - loss: 0.2740 - acc: 0.8794 - val_loss: 0.2876 - val_acc: 0.8750\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.87240 to 0.87500, saving model to data/fine_tune_aug.h5\n",
            "Epoch 3/50\n",
            "100/100 [==============================] - 1352s 14s/step - loss: 0.2440 - acc: 0.8912 - val_loss: 0.3662 - val_acc: 0.8802\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.87500 to 0.88021, saving model to data/fine_tune_aug.h5\n",
            "Epoch 4/50\n",
            "100/100 [==============================] - 1343s 13s/step - loss: 0.2449 - acc: 0.8969 - val_loss: 0.3445 - val_acc: 0.8854\n",
            "\n",
            "Epoch 00004: val_acc improved from 0.88021 to 0.88542, saving model to data/fine_tune_aug.h5\n",
            "Epoch 5/50\n",
            "100/100 [==============================] - 1514s 15s/step - loss: 0.2330 - acc: 0.9006 - val_loss: 0.3283 - val_acc: 0.8776\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.88542\n",
            "Epoch 6/50\n",
            "100/100 [==============================] - 1520s 15s/step - loss: 0.2032 - acc: 0.9106 - val_loss: 0.4025 - val_acc: 0.8698\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.88542\n",
            "Epoch 7/50\n",
            "100/100 [==============================] - 1419s 14s/step - loss: 0.2028 - acc: 0.9181 - val_loss: 0.3701 - val_acc: 0.8802\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.88542\n",
            "Epoch 8/50\n",
            "100/100 [==============================] - 1536s 15s/step - loss: 0.1791 - acc: 0.9256 - val_loss: 0.3054 - val_acc: 0.8958\n",
            "\n",
            "Epoch 00008: val_acc improved from 0.88542 to 0.89583, saving model to data/fine_tune_aug.h5\n",
            "Epoch 9/50\n",
            "100/100 [==============================] - 1472s 15s/step - loss: 0.1802 - acc: 0.9231 - val_loss: 0.3604 - val_acc: 0.8724\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.89583\n",
            "Epoch 10/50\n",
            "100/100 [==============================] - 1476s 15s/step - loss: 0.1930 - acc: 0.9175 - val_loss: 0.3209 - val_acc: 0.8854\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.89583\n",
            "Epoch 11/50\n",
            "100/100 [==============================] - 1470s 15s/step - loss: 0.1527 - acc: 0.9394 - val_loss: 0.3893 - val_acc: 0.8854\n",
            "\n",
            "Epoch 00011: val_acc did not improve from 0.89583\n",
            "Epoch 12/50\n",
            "100/100 [==============================] - 1458s 15s/step - loss: 0.1497 - acc: 0.9375 - val_loss: 0.2918 - val_acc: 0.8880\n",
            "\n",
            "Epoch 00012: val_acc did not improve from 0.89583\n",
            "Epoch 13/50\n",
            "100/100 [==============================] - 1470s 15s/step - loss: 0.1543 - acc: 0.9313 - val_loss: 0.3059 - val_acc: 0.8880\n",
            "\n",
            "Epoch 00013: val_acc did not improve from 0.89583\n",
            "Epoch 14/50\n",
            "100/100 [==============================] - 1484s 15s/step - loss: 0.1419 - acc: 0.9412 - val_loss: 0.3317 - val_acc: 0.8802\n",
            "\n",
            "Epoch 00014: val_acc did not improve from 0.89583\n",
            "Epoch 15/50\n",
            "100/100 [==============================] - 1489s 15s/step - loss: 0.1399 - acc: 0.9456 - val_loss: 0.3273 - val_acc: 0.8932\n",
            "\n",
            "Epoch 00015: val_acc did not improve from 0.89583\n",
            "Epoch 16/50\n",
            "100/100 [==============================] - 1485s 15s/step - loss: 0.1281 - acc: 0.9562 - val_loss: 0.2969 - val_acc: 0.8958\n",
            "\n",
            "Epoch 00016: val_acc did not improve from 0.89583\n",
            "Epoch 17/50\n",
            "100/100 [==============================] - 1479s 15s/step - loss: 0.1356 - acc: 0.9425 - val_loss: 0.3878 - val_acc: 0.8880\n",
            "\n",
            "Epoch 00017: val_acc did not improve from 0.89583\n",
            "Epoch 18/50\n",
            "100/100 [==============================] - 1472s 15s/step - loss: 0.1249 - acc: 0.9488 - val_loss: 0.3553 - val_acc: 0.8880\n",
            "\n",
            "Epoch 00018: val_acc did not improve from 0.89583\n",
            "Epoch 00018: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f4f6799ea58>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    }
  ]
}